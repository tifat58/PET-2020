{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pet_attack1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tifat58/PET-2020/blob/master/pet_attack1_mnist%2Bfmnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFKy8sp26lgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6ef2c7f-8383-44c8-f223-fb30699537a8"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Subset, Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# torch.cuda.set_device(device)\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvLQ6g2f62hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_target_label_idx(labels, targets, shots=5, test=False):\n",
        "    \"\"\"\n",
        "    Get the indices of labels that are included in targets.\n",
        "    :param labels: array of labels\n",
        "    :param targets: list/tuple of target labels\n",
        "    :return: list with indices of target labels\n",
        "    \"\"\"\n",
        "    final_list = []\n",
        "    #Both if and else operations seem to be the same, what would be the purpose of this?\n",
        "    for t in targets:\n",
        "        if test:\n",
        "            final_list += np.argwhere(np.isin(labels, t)).flatten().tolist()\n",
        "        else:\n",
        "            final_list += np.argwhere(np.isin(labels, t)).flatten().tolist()\n",
        "    \n",
        "    return final_list\n",
        "\n",
        "def convert_label(x):\n",
        "\n",
        "    if x >= 5:\n",
        "        return x-5\n",
        "    else:\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zNDlD9o9Q7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MNIST_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, root: str, name='MNIST', normal_class=[0,1,2,3,4,5,6,7,8,9]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.root = root\n",
        "        self.name = name\n",
        "        self.normal_classes = tuple(normal_class)     \n",
        "\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        if name == 'MNIST':\n",
        "          train_set = MyMNIST(root=self.root, train=True, download=True,\n",
        "                              transform=transform)\n",
        "          \n",
        "        elif name == 'FashionMNIST':\n",
        "          train_set = MyFashionMNIST(root=self.root, train=True, download=True,\n",
        "                              transform=transform)\n",
        "          \n",
        "        train_index = get_target_label_idx(train_set.train_labels.clone().data.cpu().numpy(), self.normal_classes)\n",
        "        random.shuffle(train_index)\n",
        "\n",
        "        train_index_half_len = int(len(train_index)/2)\n",
        "        shadow_set = Subset(train_set, train_index[0:train_index_half_len])\n",
        "        target_set = Subset(train_set, train_index[train_index_half_len:])\n",
        "\n",
        "        shadow_half_len = int(len(shadow_set)/2)\n",
        "        print(\"shadow half len: \", shadow_half_len)\n",
        "        self.shadow_train = Subset(shadow_set, list(range(0, shadow_half_len)))\n",
        "        self.shadow_test = Subset (shadow_set, list(range(shadow_half_len, len(shadow_set))))\n",
        "\n",
        "        target_half_len = int(len(target_set)/2)\n",
        "        print(\"Target half len: \", target_half_len)\n",
        "        self.target_train = Subset(target_set, list(range(0, target_half_len)))\n",
        "        self.target_unknown = Subset(target_set, list(range(target_half_len, len(target_set))))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHN3Ih1b9SXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyMNIST(MNIST):\n",
        "    \"\"\"Torchvision MNIST class with patch of __getitem__ method to also return the index of a data sample.\"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyMNIST, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Override the original method of the MNIST class.\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            triple: (image, target, index) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        # if self.train:\n",
        "        #     img, target = self.train_data[index], self.train_labels[index]\n",
        "        # else:\n",
        "        #     img, target = self.test_data[index], self.test_labels[index]\n",
        "\n",
        "        if self.train:\n",
        "            img, target = self.data[index], self.targets[index]\n",
        "        else:\n",
        "            img, target = self.test_data[index], self.targets[index]\n",
        "\n",
        "        img = Image.fromarray(img.numpy(), mode='L')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target, index  # only line changed"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsiUE8b0x88T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyFashionMNIST(FashionMNIST):\n",
        "    \"\"\"Torchvision MNIST class with patch of __getitem__ method to also return the index of a data sample.\"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(FashionMNIST, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Override the original method of the MNIST class.\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            triple: (image, target, index) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        # if self.train:\n",
        "        #     img, target = self.train_data[index], self.train_labels[index]\n",
        "        # else:\n",
        "        #     img, target = self.test_data[index], self.test_labels[index]\n",
        "\n",
        "        if self.train:\n",
        "            img, target = self.data[index], self.targets[index]\n",
        "        else:\n",
        "            img, target = self.test_data[index], self.targets[index]\n",
        "\n",
        "        img = Image.fromarray(img.numpy(), mode='L')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target, index  # only line changed"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKqfKqY80NAk",
        "colab_type": "text"
      },
      "source": [
        "**Section: MNIST Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyK-4xC89z_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4f060742-2d47-4059-fec1-beb3eea3659a"
      },
      "source": [
        "mninst_dataset = MNIST_Dataset(root='data/', name='MNIST')\n",
        "shadow_train_loader = DataLoader(mninst_dataset.shadow_train, batch_size=64, shuffle=True, num_workers=0)\n",
        "shadow_test_loader = DataLoader(mninst_dataset.shadow_test, batch_size=64, shuffle=True, num_workers=0)\n",
        "target_train_loader = DataLoader(mninst_dataset.target_train, batch_size=64, shuffle=True, num_workers=0)\n",
        "target_unk_loader = DataLoader(mninst_dataset.target_unknown, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shadow half len:  15000\n",
            "Target half len:  15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYiD8qV8_RUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "f09e1167-fd5d-4afe-d3e5-7704970ddc99"
      },
      "source": [
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(shadow_train_loader)\n",
        "images, labels, idx = dataiter.next()\n",
        "print(\"Labels: \", labels[0:8])\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[0:8]))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:  tensor([9, 8, 6, 0, 3, 8, 6, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYvoGGTDJjvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" This is the classifier model as mentioned in the paper\n",
        "\"\"\"\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
        "        self.fc1   = nn.Linear(16*5*5, 128)\n",
        "        self.fc2   = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQS5d240fYwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Attack Model Implementation \"\"\"\n",
        "\n",
        "class AttackModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "      super(AttackModel, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size  = hidden_size\n",
        "\n",
        "      self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "      self.fc2 = torch.nn.Linear(self.hidden_size, 2)\n",
        "      # self.sigmoid = torch.nn.Softmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = F.softmax(self.fc2(x))\n",
        "      output = x\n",
        "      \n",
        "      return output"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsRkS3NFpFCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZJWpThX_yv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20, attack=False):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                \n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "                \n",
        "                for data in train_loader:\n",
        "                    if attack:\n",
        "                      inputs, labels = data\n",
        "                    else:\n",
        "                      inputs, labels, idx = data\n",
        "\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    \n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(True):\n",
        "                        outputs = model(inputs)\n",
        "                        \n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        # print(preds, labels)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    \n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                    \n",
        "                    \n",
        "                scheduler.step()\n",
        "                print(running_corrects)\n",
        "                epoch_loss = running_loss / train_size\n",
        "                epoch_acc = running_corrects.double() / train_size\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Train', epoch_loss, epoch_acc))\n",
        "                    \n",
        "            else:\n",
        "                \n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "                \n",
        "                for data in test_loader:\n",
        "                    if attack:\n",
        "                      inputs, labels = data\n",
        "                    else:\n",
        "                      inputs, labels, idx = data\n",
        "                    \n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(False):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        \n",
        "                        loss = criterion(outputs, labels)\n",
        "                \n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                epoch_loss = running_loss / test_size\n",
        "                epoch_acc = running_corrects.double() / test_size\n",
        "                \n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                last_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, best_acc, last_model_wts"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk64McEqS2OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Returns top3 prediction probability given x\"\"\"\n",
        "\n",
        "def test(model, test_loader, criterion):\n",
        "  model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0\n",
        "  # prediction_list = []\n",
        "  i = 0\n",
        "  for data in test_loader:\n",
        "      inputs, labels, idx = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "     \n",
        "      with torch.set_grad_enabled(False):\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          sm = torch.nn.Softmax()\n",
        "          pred_probs = sm(outputs)\n",
        "          pred_probs, indices = torch.sort(pred_probs, descending=True)\n",
        "          # print(pred_probs)\n",
        "          if i == 0:\n",
        "            prediction_list = pred_probs[:,0:3]\n",
        "          else:\n",
        "            prediction_list = torch.cat((prediction_list, pred_probs[:,0:3]))\n",
        "          i += 1\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "  epoch_loss = running_loss / test_size\n",
        "  epoch_acc = running_corrects.double() / test_size\n",
        "\n",
        "  print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\n",
        "  \n",
        "  return prediction_list"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlWxZqSY3Cab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Attack model test function \"\"\"\n",
        "def attack_test(model, test_loader, criterion):\n",
        "  model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0\n",
        "  # prediction_list = []\n",
        "  i = 0\n",
        "  test_true_label = []\n",
        "  test_pred_label = []\n",
        "  for data in test_loader:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      with torch.set_grad_enabled(False):\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          sm = torch.nn.Softmax()\n",
        "          pred_probs = sm(outputs)\n",
        "          pred_probs, indices = torch.sort(pred_probs, descending=True)\n",
        "          # # print(pred_probs)\n",
        "          # if i == 0:\n",
        "          #   prediction_list = pred_probs[:,0:3]\n",
        "          # else:\n",
        "          #   prediction_list = torch.cat((prediction_list, pred_probs[:,0:3]))\n",
        "          # i += 1\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          test_true_label.append(labels.data)\n",
        "          test_pred_label.append(preds.data)\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "  epoch_loss = running_loss / test_size\n",
        "  epoch_acc = running_corrects.double() / test_size\n",
        "\n",
        "  print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\n",
        "  \n",
        "  return test_true_label, test_pred_label\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QGqlwo4jMZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Fuction to compute accuracy report\"\"\"\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def report(true_labels, predicted_labels):\n",
        "  target_names = ['0','1']\n",
        "  print(classification_report(true_labels, predicted_labels))\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  cm1 = confusion_matrix(true_labels, predicted_labels, labels=[1, 0])\n",
        "      \n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(cm1)\n",
        "\n",
        "  print('\\nStatistical Report:')\n",
        "  total1=sum(sum(cm1))\n",
        "  #####from confusion matrix calculate accuracy\n",
        "  accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "  print ('Acc: ', round(accuracy1, 2))\n",
        "\n",
        "  prec = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
        "  print('Precision: ', round(prec,2) )\n",
        "\n",
        "  rec = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  print('Recall: ', round(rec,2))\n",
        "\n",
        "  return accuracy1, prec, rec\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCLsCOIgLQwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8158161-93e0-454a-86db-387927ac7584"
      },
      "source": [
        "train_size = len(mninst_dataset.shadow_train)\n",
        "test_size = len(mninst_dataset.shadow_test)\n",
        "print(train_size, test_size)\n",
        "net = LeNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(net.parameters(), lr=0.001)\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "best_net, best_acc, last_net = train_model(net, shadow_train_loader, shadow_test_loader, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                        num_epochs=30)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000 15000\n",
            "Epoch 0/29\n",
            "----------\n",
            "tensor(12308)\n",
            "Train Loss: 0.5984 Acc: 0.8205\n",
            "Val Loss: 0.2334 Acc: 0.9275\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(14181)\n",
            "Train Loss: 0.1789 Acc: 0.9454\n",
            "Val Loss: 0.1586 Acc: 0.9522\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(14452)\n",
            "Train Loss: 0.1167 Acc: 0.9635\n",
            "Val Loss: 0.1143 Acc: 0.9671\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(14586)\n",
            "Train Loss: 0.0899 Acc: 0.9724\n",
            "Val Loss: 0.0975 Acc: 0.9705\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(14647)\n",
            "Train Loss: 0.0731 Acc: 0.9765\n",
            "Val Loss: 0.0927 Acc: 0.9723\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(14722)\n",
            "Train Loss: 0.0599 Acc: 0.9815\n",
            "Val Loss: 0.0826 Acc: 0.9756\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(14786)\n",
            "Train Loss: 0.0475 Acc: 0.9857\n",
            "Val Loss: 0.0800 Acc: 0.9759\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(14879)\n",
            "Train Loss: 0.0292 Acc: 0.9919\n",
            "Val Loss: 0.0693 Acc: 0.9792\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(14894)\n",
            "Train Loss: 0.0261 Acc: 0.9929\n",
            "Val Loss: 0.0686 Acc: 0.9807\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(14910)\n",
            "Train Loss: 0.0246 Acc: 0.9940\n",
            "Val Loss: 0.0685 Acc: 0.9797\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(14911)\n",
            "Train Loss: 0.0235 Acc: 0.9941\n",
            "Val Loss: 0.0694 Acc: 0.9795\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(14918)\n",
            "Train Loss: 0.0225 Acc: 0.9945\n",
            "Val Loss: 0.0682 Acc: 0.9812\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(14919)\n",
            "Train Loss: 0.0217 Acc: 0.9946\n",
            "Val Loss: 0.0677 Acc: 0.9802\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(14930)\n",
            "Train Loss: 0.0206 Acc: 0.9953\n",
            "Val Loss: 0.0681 Acc: 0.9807\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(14939)\n",
            "Train Loss: 0.0188 Acc: 0.9959\n",
            "Val Loss: 0.0676 Acc: 0.9807\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(14942)\n",
            "Train Loss: 0.0184 Acc: 0.9961\n",
            "Val Loss: 0.0676 Acc: 0.9809\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(14944)\n",
            "Train Loss: 0.0182 Acc: 0.9963\n",
            "Val Loss: 0.0676 Acc: 0.9807\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(14945)\n",
            "Train Loss: 0.0181 Acc: 0.9963\n",
            "Val Loss: 0.0677 Acc: 0.9806\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(14945)\n",
            "Train Loss: 0.0180 Acc: 0.9963\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(14943)\n",
            "Train Loss: 0.0178 Acc: 0.9962\n",
            "Val Loss: 0.0678 Acc: 0.9805\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(14945)\n",
            "Train Loss: 0.0177 Acc: 0.9963\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0174 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0173 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(14947)\n",
            "Train Loss: 0.0173 Acc: 0.9965\n",
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "\n",
            "Training complete in 3m 32s\n",
            "Best val Acc: 0.981200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc3hKkTj5niM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "b245a544-e4fa-4bd0-d890-a3d5df8a8260"
      },
      "source": [
        "print(\"Shadow model Test set predictions: \")\n",
        "train_size = len(mninst_dataset.shadow_train)\n",
        "test_size = len(mninst_dataset.shadow_test)\n",
        "print(train_size, test_size)\n",
        "\n",
        "s_net = LeNet().to(device)\n",
        "s_net.load_state_dict(last_net)\n",
        "\n",
        "shadow_test_prediction = test(s_net, shadow_test_loader, criterion)\n",
        "print(\"Shadow model Train set predictions: \")\n",
        "shadow_train_prediction = test(s_net, shadow_train_loader, criterion)\n",
        "\n",
        "d1 = torch.utils.data.TensorDataset(shadow_train_prediction, torch.ones(train_size, dtype=torch.long))\n",
        "d2 = torch.utils.data.TensorDataset(shadow_test_prediction, torch.zeros(test_size, dtype=torch.long))\n",
        "shadow_trained_dataset = torch.utils.data.ConcatDataset([d1, d2])\n",
        "len(shadow_trained_dataset)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shadow model Test set predictions: \n",
            "15000 15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0678 Acc: 0.9807\n",
            "Shadow model Train set predictions: \n",
            "Val Loss: 0.0173 Acc: 0.9965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkl6M42oHm80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90cbf284-9f06-4b6e-ee5e-9570c8ccd44b"
      },
      "source": [
        "print(\"Sample data: \", shadow_trained_dataset[17223][0], \"label\", shadow_trained_dataset[17223][1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample data:  tensor([9.9997e-01, 2.1933e-05, 2.7650e-06]) label tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi_uqntJR3om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5936d4a0-c12d-44bc-d451-ef828e904794"
      },
      "source": [
        "\"\"\" Training Target model \"\"\"\n",
        "train_size = len(mninst_dataset.target_train)\n",
        "test_size = len(mninst_dataset.target_unknown)\n",
        "target_net = LeNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(target_net.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "target_best_net, target_best_acc, target_last_net = train_model(target_net, target_train_loader, target_unk_loader, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                        num_epochs=30)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(12291)\n",
            "Train Loss: 0.6317 Acc: 0.8194\n",
            "Val Loss: 0.2185 Acc: 0.9364\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(14184)\n",
            "Train Loss: 0.1791 Acc: 0.9456\n",
            "Val Loss: 0.1194 Acc: 0.9632\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(14453)\n",
            "Train Loss: 0.1214 Acc: 0.9635\n",
            "Val Loss: 0.0942 Acc: 0.9713\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(14587)\n",
            "Train Loss: 0.0899 Acc: 0.9725\n",
            "Val Loss: 0.0791 Acc: 0.9757\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(14651)\n",
            "Train Loss: 0.0745 Acc: 0.9767\n",
            "Val Loss: 0.0773 Acc: 0.9762\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(14710)\n",
            "Train Loss: 0.0614 Acc: 0.9807\n",
            "Val Loss: 0.0691 Acc: 0.9783\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(14745)\n",
            "Train Loss: 0.0515 Acc: 0.9830\n",
            "Val Loss: 0.0622 Acc: 0.9805\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(14773)\n",
            "Train Loss: 0.0457 Acc: 0.9849\n",
            "Val Loss: 0.0687 Acc: 0.9785\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(14795)\n",
            "Train Loss: 0.0400 Acc: 0.9863\n",
            "Val Loss: 0.0555 Acc: 0.9829\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(14833)\n",
            "Train Loss: 0.0334 Acc: 0.9889\n",
            "Val Loss: 0.0677 Acc: 0.9795\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(14865)\n",
            "Train Loss: 0.0275 Acc: 0.9910\n",
            "Val Loss: 0.0586 Acc: 0.9824\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(14870)\n",
            "Train Loss: 0.0266 Acc: 0.9913\n",
            "Val Loss: 0.0624 Acc: 0.9811\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(14880)\n",
            "Train Loss: 0.0236 Acc: 0.9920\n",
            "Val Loss: 0.0735 Acc: 0.9790\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(14907)\n",
            "Train Loss: 0.0189 Acc: 0.9938\n",
            "Val Loss: 0.0719 Acc: 0.9798\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(14941)\n",
            "Train Loss: 0.0123 Acc: 0.9961\n",
            "Val Loss: 0.0705 Acc: 0.9804\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(14930)\n",
            "Train Loss: 0.0131 Acc: 0.9953\n",
            "Val Loss: 0.0627 Acc: 0.9837\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(14960)\n",
            "Train Loss: 0.0089 Acc: 0.9973\n",
            "Val Loss: 0.0637 Acc: 0.9847\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(14946)\n",
            "Train Loss: 0.0110 Acc: 0.9964\n",
            "Val Loss: 0.0877 Acc: 0.9773\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(14939)\n",
            "Train Loss: 0.0127 Acc: 0.9959\n",
            "Val Loss: 0.0670 Acc: 0.9844\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(14974)\n",
            "Train Loss: 0.0065 Acc: 0.9983\n",
            "Val Loss: 0.0656 Acc: 0.9843\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(14977)\n",
            "Train Loss: 0.0062 Acc: 0.9985\n",
            "Val Loss: 0.0689 Acc: 0.9843\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(14963)\n",
            "Train Loss: 0.0074 Acc: 0.9975\n",
            "Val Loss: 0.0831 Acc: 0.9800\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(14932)\n",
            "Train Loss: 0.0139 Acc: 0.9955\n",
            "Val Loss: 0.0753 Acc: 0.9824\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(14944)\n",
            "Train Loss: 0.0095 Acc: 0.9963\n",
            "Val Loss: 0.0807 Acc: 0.9827\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(14944)\n",
            "Train Loss: 0.0104 Acc: 0.9963\n",
            "Val Loss: 0.0713 Acc: 0.9831\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(14974)\n",
            "Train Loss: 0.0048 Acc: 0.9983\n",
            "Val Loss: 0.0680 Acc: 0.9846\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(14989)\n",
            "Train Loss: 0.0030 Acc: 0.9993\n",
            "Val Loss: 0.0706 Acc: 0.9855\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(14985)\n",
            "Train Loss: 0.0034 Acc: 0.9990\n",
            "Val Loss: 0.0923 Acc: 0.9823\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(14954)\n",
            "Train Loss: 0.0094 Acc: 0.9969\n",
            "Val Loss: 0.0922 Acc: 0.9804\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(14973)\n",
            "Train Loss: 0.0053 Acc: 0.9982\n",
            "Val Loss: 0.0799 Acc: 0.9837\n",
            "\n",
            "Training complete in 3m 33s\n",
            "Best val Acc: 0.985533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiV9FNwKUjGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b226fc89-b5b5-4181-d2ce-d731d989da69"
      },
      "source": [
        "train_size = len(mninst_dataset.target_train)\n",
        "test_size = len(mninst_dataset.target_unknown)\n",
        "\n",
        "t_net = LeNet().to(device)\n",
        "t_net.load_state_dict(target_last_net)\n",
        "\n",
        "target_test_prediction = test(t_net, target_unk_loader, criterion)\n",
        "target_train_prediction = test(t_net, target_train_loader, criterion)\n",
        "\n",
        "d1 = torch.utils.data.TensorDataset(target_train_prediction, torch.ones(train_size, dtype=torch.long))\n",
        "d2 = torch.utils.data.TensorDataset(target_test_prediction, torch.zeros(test_size, dtype=torch.long))\n",
        "target_trained_dataset = torch.utils.data.ConcatDataset([d1, d2])\n",
        "len(target_trained_dataset)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0799 Acc: 0.9837\n",
            "Val Loss: 0.0023 Acc: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4uQuJrZ8SEh",
        "colab_type": "text"
      },
      "source": [
        "**Attack Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6btvC6siqXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b34a9db0-36a1-48b2-861f-fc01214e234c"
      },
      "source": [
        "train_size = len(shadow_trained_dataset)\n",
        "test_size = len(target_trained_dataset)\n",
        "attack_model = AttackModel(3, 64).to(device)\n",
        "\n",
        "atk_train_loader = DataLoader(shadow_trained_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
        "atk_test_loader = DataLoader(target_trained_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
        "optimizer_ft = optim.Adam(attack_model.parameters(), lr=0.01, weight_decay=1e-6)\n",
        "\n",
        "attack_best_net, attack_best_acc, attack_last_net = train_model(attack_model, atk_train_loader, atk_test_loader, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=40, attack=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(14916)\n",
            "Train Loss: 0.6947 Acc: 0.4972\n",
            "Val Loss: 0.6920 Acc: 0.5000\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "tensor(15075)\n",
            "Train Loss: 0.6944 Acc: 0.5025\n",
            "Val Loss: 0.6926 Acc: 0.5088\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "tensor(15144)\n",
            "Train Loss: 0.6947 Acc: 0.5048\n",
            "Val Loss: 0.6924 Acc: 0.5085\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "tensor(15088)\n",
            "Train Loss: 0.6938 Acc: 0.5029\n",
            "Val Loss: 0.6928 Acc: 0.5080\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "tensor(15111)\n",
            "Train Loss: 0.6942 Acc: 0.5037\n",
            "Val Loss: 0.6958 Acc: 0.5000\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "tensor(15191)\n",
            "Train Loss: 0.6941 Acc: 0.5064\n",
            "Val Loss: 0.6932 Acc: 0.5000\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "tensor(15110)\n",
            "Train Loss: 0.6938 Acc: 0.5037\n",
            "Val Loss: 0.6916 Acc: 0.5095\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "tensor(15122)\n",
            "Train Loss: 0.6946 Acc: 0.5041\n",
            "Val Loss: 0.6931 Acc: 0.5074\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "tensor(15046)\n",
            "Train Loss: 0.6943 Acc: 0.5015\n",
            "Val Loss: 0.6917 Acc: 0.5106\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "tensor(15146)\n",
            "Train Loss: 0.6943 Acc: 0.5049\n",
            "Val Loss: 0.6930 Acc: 0.5078\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "tensor(14956)\n",
            "Train Loss: 0.6943 Acc: 0.4985\n",
            "Val Loss: 0.7006 Acc: 0.5075\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "tensor(14984)\n",
            "Train Loss: 0.6943 Acc: 0.4995\n",
            "Val Loss: 0.6916 Acc: 0.5097\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "tensor(15129)\n",
            "Train Loss: 0.6945 Acc: 0.5043\n",
            "Val Loss: 0.6919 Acc: 0.5095\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "tensor(14980)\n",
            "Train Loss: 0.6949 Acc: 0.4993\n",
            "Val Loss: 0.6932 Acc: 0.5006\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "tensor(15192)\n",
            "Train Loss: 0.6935 Acc: 0.5064\n",
            "Val Loss: 0.6958 Acc: 0.5000\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "tensor(15166)\n",
            "Train Loss: 0.6941 Acc: 0.5055\n",
            "Val Loss: 0.6940 Acc: 0.5000\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "tensor(15067)\n",
            "Train Loss: 0.6941 Acc: 0.5022\n",
            "Val Loss: 0.6918 Acc: 0.5093\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "tensor(15035)\n",
            "Train Loss: 0.6938 Acc: 0.5012\n",
            "Val Loss: 0.6948 Acc: 0.5000\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "tensor(15137)\n",
            "Train Loss: 0.6943 Acc: 0.5046\n",
            "Val Loss: 0.6924 Acc: 0.5097\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "tensor(14998)\n",
            "Train Loss: 0.6942 Acc: 0.4999\n",
            "Val Loss: 0.6930 Acc: 0.5000\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "tensor(15011)\n",
            "Train Loss: 0.6943 Acc: 0.5004\n",
            "Val Loss: 0.6917 Acc: 0.5000\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "tensor(15009)\n",
            "Train Loss: 0.6937 Acc: 0.5003\n",
            "Val Loss: 0.6917 Acc: 0.5000\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "tensor(14988)\n",
            "Train Loss: 0.6945 Acc: 0.4996\n",
            "Val Loss: 0.6927 Acc: 0.5077\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "tensor(15193)\n",
            "Train Loss: 0.6940 Acc: 0.5064\n",
            "Val Loss: 0.6922 Acc: 0.5000\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "tensor(15187)\n",
            "Train Loss: 0.6936 Acc: 0.5062\n",
            "Val Loss: 0.6920 Acc: 0.5096\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "tensor(15151)\n",
            "Train Loss: 0.6945 Acc: 0.5050\n",
            "Val Loss: 0.6924 Acc: 0.5085\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "tensor(15046)\n",
            "Train Loss: 0.6942 Acc: 0.5015\n",
            "Val Loss: 0.6914 Acc: 0.5097\n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "tensor(15161)\n",
            "Train Loss: 0.6937 Acc: 0.5054\n",
            "Val Loss: 0.6922 Acc: 0.5000\n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "tensor(15113)\n",
            "Train Loss: 0.6943 Acc: 0.5038\n",
            "Val Loss: 0.6919 Acc: 0.5000\n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "tensor(14973)\n",
            "Train Loss: 0.6939 Acc: 0.4991\n",
            "Val Loss: 0.6916 Acc: 0.5097\n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "tensor(15173)\n",
            "Train Loss: 0.6939 Acc: 0.5058\n",
            "Val Loss: 0.6917 Acc: 0.5110\n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "tensor(15109)\n",
            "Train Loss: 0.6939 Acc: 0.5036\n",
            "Val Loss: 0.6916 Acc: 0.5097\n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "tensor(15115)\n",
            "Train Loss: 0.6947 Acc: 0.5038\n",
            "Val Loss: 0.6913 Acc: 0.5000\n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "tensor(14976)\n",
            "Train Loss: 0.6941 Acc: 0.4992\n",
            "Val Loss: 0.6928 Acc: 0.5078\n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "tensor(15207)\n",
            "Train Loss: 0.6938 Acc: 0.5069\n",
            "Val Loss: 0.6920 Acc: 0.5094\n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "tensor(15116)\n",
            "Train Loss: 0.6940 Acc: 0.5039\n",
            "Val Loss: 0.6921 Acc: 0.5000\n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "tensor(15210)\n",
            "Train Loss: 0.6938 Acc: 0.5070\n",
            "Val Loss: 0.6922 Acc: 0.5090\n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "tensor(15242)\n",
            "Train Loss: 0.6941 Acc: 0.5081\n",
            "Val Loss: 0.6923 Acc: 0.5090\n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "tensor(15099)\n",
            "Train Loss: 0.6938 Acc: 0.5033\n",
            "Val Loss: 0.6942 Acc: 0.5075\n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "tensor(15022)\n",
            "Train Loss: 0.6948 Acc: 0.5007\n",
            "Val Loss: 0.6921 Acc: 0.5000\n",
            "\n",
            "Training complete in 2m 28s\n",
            "Best val Acc: 0.511000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDE18uHFzO8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "769038d5-4637-4802-b09d-415da8f0fd7a"
      },
      "source": [
        "a_net = AttackModel(3, 64).to(device)\n",
        "a_net.load_state_dict(attack_last_net)\n",
        "t_l, t_p = attack_test(attack_best_net, atk_test_loader, criterion)\n",
        "l_true = []\n",
        "l_pred = []\n",
        "for d in t_l:\n",
        "    l_list = d.cpu().numpy()\n",
        "    for l in l_list:\n",
        "        l_true.append(l)\n",
        "# print(l_true)\n",
        "for d in t_p:\n",
        "    l_list = d.cpu().numpy()\n",
        "    for l in l_list:\n",
        "        l_pred.append(l)\n",
        "# print(l_pred)\n",
        "mnist_acc, mnist_prec, mnist_rec = report(l_true, l_pred)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6917 Acc: 0.5110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.04      0.08     15000\n",
            "           1       0.51      0.98      0.67     15000\n",
            "\n",
            "    accuracy                           0.51     30000\n",
            "   macro avg       0.59      0.51      0.37     30000\n",
            "weighted avg       0.59      0.51      0.37     30000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[14700   300]\n",
            " [14370   630]]\n",
            "\n",
            "Statistical Report:\n",
            "Acc:  0.51\n",
            "Precision:  0.51\n",
            "Recall:  0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeP1EDxVCNRB",
        "colab_type": "text"
      },
      "source": [
        "**Section: Fashion MNIST Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4314iR-NCRFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "09b284cb-ceed-4e8e-c366-f09c78836eb7"
      },
      "source": [
        "fashion_mninst_dataset = MNIST_Dataset(root='data/', name='FashionMNIST')\n",
        "shadow_train_loader = DataLoader(fashion_mninst_dataset.shadow_train, batch_size=64, shuffle=True, num_workers=0)\n",
        "shadow_test_loader = DataLoader(fashion_mninst_dataset.shadow_test, batch_size=64, shuffle=True, num_workers=0)\n",
        "target_train_loader = DataLoader(fashion_mninst_dataset.target_train, batch_size=64, shuffle=True, num_workers=0)\n",
        "target_unk_loader = DataLoader(fashion_mninst_dataset.target_unknown, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shadow half len:  15000\n",
            "Target half len:  15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CkwXv8YCvB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "cea3985e-1dea-4de9-83bb-b2884eacdb1b"
      },
      "source": [
        "\n",
        "# get some random training images\n",
        "dataiter = iter(shadow_train_loader)\n",
        "images, labels, idx = dataiter.next()\n",
        "print(\"Labels: \", labels[0:8])\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[0:8]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:  tensor([1, 0, 6, 8, 9, 1, 7, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qskgb9ZwC2Cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a3039ec-af9d-4fbf-dcf2-6145ce339b43"
      },
      "source": [
        "train_size = len(fashion_mninst_dataset.shadow_train)\n",
        "test_size = len(fashion_mninst_dataset.shadow_test)\n",
        "print(train_size, test_size)\n",
        "fashion_net = LeNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(fashion_net.parameters(), lr=0.001)\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "best_net, best_acc, last_net = train_model(fashion_net, shadow_train_loader, shadow_test_loader, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                        num_epochs=30)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000 15000\n",
            "Epoch 0/29\n",
            "----------\n",
            "tensor(10190)\n",
            "Train Loss: 0.9138 Acc: 0.6793\n",
            "Val Loss: 0.6385 Acc: 0.7647\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(11846)\n",
            "Train Loss: 0.5707 Acc: 0.7897\n",
            "Val Loss: 0.5778 Acc: 0.7916\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(12421)\n",
            "Train Loss: 0.4807 Acc: 0.8281\n",
            "Val Loss: 0.4679 Acc: 0.8353\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(12662)\n",
            "Train Loss: 0.4254 Acc: 0.8441\n",
            "Val Loss: 0.4473 Acc: 0.8381\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(12852)\n",
            "Train Loss: 0.3951 Acc: 0.8568\n",
            "Val Loss: 0.4116 Acc: 0.8492\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(13061)\n",
            "Train Loss: 0.3645 Acc: 0.8707\n",
            "Val Loss: 0.3845 Acc: 0.8609\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(13170)\n",
            "Train Loss: 0.3456 Acc: 0.8780\n",
            "Val Loss: 0.4066 Acc: 0.8533\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(13342)\n",
            "Train Loss: 0.3109 Acc: 0.8895\n",
            "Val Loss: 0.3588 Acc: 0.8711\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(13384)\n",
            "Train Loss: 0.3034 Acc: 0.8923\n",
            "Val Loss: 0.3553 Acc: 0.8729\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(13380)\n",
            "Train Loss: 0.3003 Acc: 0.8920\n",
            "Val Loss: 0.3541 Acc: 0.8730\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(13408)\n",
            "Train Loss: 0.2979 Acc: 0.8939\n",
            "Val Loss: 0.3529 Acc: 0.8733\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(13414)\n",
            "Train Loss: 0.2959 Acc: 0.8943\n",
            "Val Loss: 0.3510 Acc: 0.8744\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(13441)\n",
            "Train Loss: 0.2937 Acc: 0.8961\n",
            "Val Loss: 0.3506 Acc: 0.8738\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(13439)\n",
            "Train Loss: 0.2918 Acc: 0.8959\n",
            "Val Loss: 0.3503 Acc: 0.8746\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(13485)\n",
            "Train Loss: 0.2863 Acc: 0.8990\n",
            "Val Loss: 0.3483 Acc: 0.8765\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(13490)\n",
            "Train Loss: 0.2857 Acc: 0.8993\n",
            "Val Loss: 0.3480 Acc: 0.8769\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(13492)\n",
            "Train Loss: 0.2853 Acc: 0.8995\n",
            "Val Loss: 0.3480 Acc: 0.8758\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(13481)\n",
            "Train Loss: 0.2851 Acc: 0.8987\n",
            "Val Loss: 0.3477 Acc: 0.8765\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(13500)\n",
            "Train Loss: 0.2848 Acc: 0.9000\n",
            "Val Loss: 0.3476 Acc: 0.8771\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(13494)\n",
            "Train Loss: 0.2845 Acc: 0.8996\n",
            "Val Loss: 0.3476 Acc: 0.8762\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(13496)\n",
            "Train Loss: 0.2841 Acc: 0.8997\n",
            "Val Loss: 0.3477 Acc: 0.8763\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(13489)\n",
            "Train Loss: 0.2839 Acc: 0.8993\n",
            "Val Loss: 0.3475 Acc: 0.8770\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(13500)\n",
            "Train Loss: 0.2837 Acc: 0.9000\n",
            "Val Loss: 0.3474 Acc: 0.8773\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(13502)\n",
            "Train Loss: 0.2836 Acc: 0.9001\n",
            "Val Loss: 0.3473 Acc: 0.8769\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(13505)\n",
            "Train Loss: 0.2835 Acc: 0.9003\n",
            "Val Loss: 0.3473 Acc: 0.8769\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(13507)\n",
            "Train Loss: 0.2835 Acc: 0.9005\n",
            "Val Loss: 0.3473 Acc: 0.8765\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(13504)\n",
            "Train Loss: 0.2835 Acc: 0.9003\n",
            "Val Loss: 0.3473 Acc: 0.8765\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(13506)\n",
            "Train Loss: 0.2835 Acc: 0.9004\n",
            "Val Loss: 0.3473 Acc: 0.8762\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(13507)\n",
            "Train Loss: 0.2834 Acc: 0.9005\n",
            "Val Loss: 0.3473 Acc: 0.8762\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(13507)\n",
            "Train Loss: 0.2834 Acc: 0.9005\n",
            "Val Loss: 0.3473 Acc: 0.8762\n",
            "\n",
            "Training complete in 3m 46s\n",
            "Best val Acc: 0.877267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NETaAMIE9T0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "6cb15978-0359-41bd-cc2a-f0b65cb3a524"
      },
      "source": [
        "print(\"Shadow model Test set predictions: \")\n",
        "train_size = len(mninst_dataset.shadow_train)\n",
        "test_size = len(mninst_dataset.shadow_test)\n",
        "print(train_size, test_size)\n",
        "\n",
        "s_net = LeNet().to(device)\n",
        "s_net.load_state_dict(last_net)\n",
        "\n",
        "shadow_test_prediction = test(s_net, shadow_test_loader, criterion)\n",
        "print(\"Shadow model Train set predictions: \")\n",
        "shadow_train_prediction = test(s_net, shadow_train_loader, criterion)\n",
        "\n",
        "d1 = torch.utils.data.TensorDataset(shadow_train_prediction, torch.ones(train_size, dtype=torch.long))\n",
        "d2 = torch.utils.data.TensorDataset(shadow_test_prediction, torch.zeros(test_size, dtype=torch.long))\n",
        "shadow_trained_dataset = torch.utils.data.ConcatDataset([d1, d2])\n",
        "len(shadow_trained_dataset)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shadow model Test set predictions: \n",
            "15000 15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.3473 Acc: 0.8762\n",
            "Shadow model Train set predictions: \n",
            "Val Loss: 0.2834 Acc: 0.9005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1BTJi8uFryX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6713b94-24fc-4ce8-f744-d4dd7de46669"
      },
      "source": [
        "\"\"\" Training Target model \"\"\"\n",
        "train_size = len(fashion_mninst_dataset.target_train)\n",
        "test_size = len(fashion_mninst_dataset.target_unknown)\n",
        "fashion_target_net = LeNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(fashion_target_net.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "target_best_net, target_best_acc, target_last_net = train_model(fashion_target_net, target_train_loader, target_unk_loader, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                        num_epochs=30)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(10250)\n",
            "Train Loss: 0.8902 Acc: 0.6833\n",
            "Val Loss: 0.6269 Acc: 0.7603\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(11792)\n",
            "Train Loss: 0.5736 Acc: 0.7861\n",
            "Val Loss: 0.5329 Acc: 0.8036\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(12299)\n",
            "Train Loss: 0.4945 Acc: 0.8199\n",
            "Val Loss: 0.4828 Acc: 0.8216\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(12551)\n",
            "Train Loss: 0.4522 Acc: 0.8367\n",
            "Val Loss: 0.4415 Acc: 0.8417\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(12766)\n",
            "Train Loss: 0.4200 Acc: 0.8511\n",
            "Val Loss: 0.4158 Acc: 0.8519\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(12903)\n",
            "Train Loss: 0.3921 Acc: 0.8602\n",
            "Val Loss: 0.4189 Acc: 0.8459\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(13039)\n",
            "Train Loss: 0.3657 Acc: 0.8693\n",
            "Val Loss: 0.3838 Acc: 0.8613\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(13099)\n",
            "Train Loss: 0.3531 Acc: 0.8733\n",
            "Val Loss: 0.3804 Acc: 0.8633\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(13195)\n",
            "Train Loss: 0.3349 Acc: 0.8797\n",
            "Val Loss: 0.3600 Acc: 0.8711\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(13274)\n",
            "Train Loss: 0.3199 Acc: 0.8849\n",
            "Val Loss: 0.4014 Acc: 0.8584\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(13241)\n",
            "Train Loss: 0.3132 Acc: 0.8827\n",
            "Val Loss: 0.3607 Acc: 0.8756\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(13391)\n",
            "Train Loss: 0.2965 Acc: 0.8927\n",
            "Val Loss: 0.3576 Acc: 0.8735\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(13438)\n",
            "Train Loss: 0.2861 Acc: 0.8959\n",
            "Val Loss: 0.3808 Acc: 0.8613\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(13486)\n",
            "Train Loss: 0.2758 Acc: 0.8991\n",
            "Val Loss: 0.3545 Acc: 0.8743\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(13522)\n",
            "Train Loss: 0.2615 Acc: 0.9015\n",
            "Val Loss: 0.3533 Acc: 0.8765\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(13570)\n",
            "Train Loss: 0.2533 Acc: 0.9047\n",
            "Val Loss: 0.3362 Acc: 0.8851\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(13644)\n",
            "Train Loss: 0.2370 Acc: 0.9096\n",
            "Val Loss: 0.3377 Acc: 0.8805\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(13731)\n",
            "Train Loss: 0.2337 Acc: 0.9154\n",
            "Val Loss: 0.3710 Acc: 0.8756\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(13706)\n",
            "Train Loss: 0.2274 Acc: 0.9137\n",
            "Val Loss: 0.3372 Acc: 0.8815\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(13764)\n",
            "Train Loss: 0.2160 Acc: 0.9176\n",
            "Val Loss: 0.3767 Acc: 0.8745\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(13835)\n",
            "Train Loss: 0.2085 Acc: 0.9223\n",
            "Val Loss: 0.3346 Acc: 0.8877\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(13853)\n",
            "Train Loss: 0.2032 Acc: 0.9235\n",
            "Val Loss: 0.3348 Acc: 0.8833\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(13956)\n",
            "Train Loss: 0.1946 Acc: 0.9304\n",
            "Val Loss: 0.3422 Acc: 0.8840\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(14020)\n",
            "Train Loss: 0.1796 Acc: 0.9347\n",
            "Val Loss: 0.3434 Acc: 0.8841\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(14022)\n",
            "Train Loss: 0.1741 Acc: 0.9348\n",
            "Val Loss: 0.3431 Acc: 0.8857\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(14044)\n",
            "Train Loss: 0.1704 Acc: 0.9363\n",
            "Val Loss: 0.3666 Acc: 0.8799\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(14120)\n",
            "Train Loss: 0.1601 Acc: 0.9413\n",
            "Val Loss: 0.3572 Acc: 0.8862\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(14116)\n",
            "Train Loss: 0.1584 Acc: 0.9411\n",
            "Val Loss: 0.3576 Acc: 0.8823\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(14160)\n",
            "Train Loss: 0.1485 Acc: 0.9440\n",
            "Val Loss: 0.3690 Acc: 0.8839\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(14202)\n",
            "Train Loss: 0.1430 Acc: 0.9468\n",
            "Val Loss: 0.3718 Acc: 0.8847\n",
            "\n",
            "Training complete in 3m 44s\n",
            "Best val Acc: 0.887667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeJ-7-8KGUMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "52d6ad13-6ded-4dac-97c0-9c6be96b3cf8"
      },
      "source": [
        "train_size = len(fashion_mninst_dataset.target_train)\n",
        "test_size = len(fashion_mninst_dataset.target_unknown)\n",
        "\n",
        "t_net = LeNet().to(device)\n",
        "t_net.load_state_dict(target_last_net)\n",
        "\n",
        "target_test_prediction = test(t_net, target_unk_loader, criterion)\n",
        "target_train_prediction = test(t_net, target_train_loader, criterion)\n",
        "\n",
        "d1 = torch.utils.data.TensorDataset(target_train_prediction, torch.ones(train_size, dtype=torch.long))\n",
        "d2 = torch.utils.data.TensorDataset(target_test_prediction, torch.zeros(test_size, dtype=torch.long))\n",
        "target_trained_dataset = torch.utils.data.ConcatDataset([d1, d2])\n",
        "len(target_trained_dataset)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.3718 Acc: 0.8847\n",
            "Val Loss: 0.1189 Acc: 0.9593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGjc9V9YG-Km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67698dcb-8007-4e11-9062-b6f17bd941b8"
      },
      "source": [
        "train_size = len(shadow_trained_dataset)\n",
        "test_size = len(target_trained_dataset)\n",
        "fashion_attack_model = AttackModel(3, 64).to(device)\n",
        "\n",
        "atk_train_loader = DataLoader(shadow_trained_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "atk_test_loader = DataLoader(target_trained_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "optimizer_ft = optim.Adam(fashion_attack_model.parameters(), lr=0.01, weight_decay=1e-6)\n",
        "\n",
        "attack_best_net, attack_best_acc, attack_last_net = train_model(fashion_attack_model, atk_train_loader, atk_test_loader, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=40, attack=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(14867)\n",
            "Train Loss: 0.6953 Acc: 0.4956\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "tensor(15144)\n",
            "Train Loss: 0.6939 Acc: 0.5048\n",
            "Val Loss: 0.6928 Acc: 0.5131\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "tensor(14959)\n",
            "Train Loss: 0.6936 Acc: 0.4986\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "tensor(15010)\n",
            "Train Loss: 0.6935 Acc: 0.5003\n",
            "Val Loss: 0.6933 Acc: 0.4846\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "tensor(14960)\n",
            "Train Loss: 0.6937 Acc: 0.4987\n",
            "Val Loss: 0.6935 Acc: 0.5000\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "tensor(15116)\n",
            "Train Loss: 0.6936 Acc: 0.5039\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "tensor(15093)\n",
            "Train Loss: 0.6935 Acc: 0.5031\n",
            "Val Loss: 0.6928 Acc: 0.5000\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "tensor(14954)\n",
            "Train Loss: 0.6937 Acc: 0.4985\n",
            "Val Loss: 0.6930 Acc: 0.5169\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "tensor(14956)\n",
            "Train Loss: 0.6938 Acc: 0.4985\n",
            "Val Loss: 0.6935 Acc: 0.5000\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "tensor(14929)\n",
            "Train Loss: 0.6936 Acc: 0.4976\n",
            "Val Loss: 0.6930 Acc: 0.5084\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "tensor(14875)\n",
            "Train Loss: 0.6942 Acc: 0.4958\n",
            "Val Loss: 0.6930 Acc: 0.5081\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "tensor(14941)\n",
            "Train Loss: 0.6935 Acc: 0.4980\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "tensor(15016)\n",
            "Train Loss: 0.6937 Acc: 0.5005\n",
            "Val Loss: 0.6927 Acc: 0.5144\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "tensor(14870)\n",
            "Train Loss: 0.6938 Acc: 0.4957\n",
            "Val Loss: 0.6930 Acc: 0.5000\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "tensor(15048)\n",
            "Train Loss: 0.6937 Acc: 0.5016\n",
            "Val Loss: 0.6930 Acc: 0.5000\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "tensor(14873)\n",
            "Train Loss: 0.6938 Acc: 0.4958\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "tensor(14841)\n",
            "Train Loss: 0.6938 Acc: 0.4947\n",
            "Val Loss: 0.6932 Acc: 0.5058\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "tensor(15073)\n",
            "Train Loss: 0.6937 Acc: 0.5024\n",
            "Val Loss: 0.6936 Acc: 0.5000\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "tensor(14954)\n",
            "Train Loss: 0.6937 Acc: 0.4985\n",
            "Val Loss: 0.6931 Acc: 0.5016\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "tensor(14954)\n",
            "Train Loss: 0.6935 Acc: 0.4985\n",
            "Val Loss: 0.6930 Acc: 0.4998\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "tensor(14905)\n",
            "Train Loss: 0.6935 Acc: 0.4968\n",
            "Val Loss: 0.6931 Acc: 0.5000\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "tensor(15154)\n",
            "Train Loss: 0.6937 Acc: 0.5051\n",
            "Val Loss: 0.6930 Acc: 0.5000\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "tensor(15006)\n",
            "Train Loss: 0.6936 Acc: 0.5002\n",
            "Val Loss: 0.6934 Acc: 0.5000\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "tensor(15118)\n",
            "Train Loss: 0.6936 Acc: 0.5039\n",
            "Val Loss: 0.6931 Acc: 0.5000\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "tensor(14936)\n",
            "Train Loss: 0.6939 Acc: 0.4979\n",
            "Val Loss: 0.6929 Acc: 0.5140\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "tensor(14907)\n",
            "Train Loss: 0.6935 Acc: 0.4969\n",
            "Val Loss: 0.6928 Acc: 0.5158\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "tensor(15072)\n",
            "Train Loss: 0.6935 Acc: 0.5024\n",
            "Val Loss: 0.6952 Acc: 0.5000\n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "tensor(14980)\n",
            "Train Loss: 0.6943 Acc: 0.4993\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "tensor(15035)\n",
            "Train Loss: 0.6935 Acc: 0.5012\n",
            "Val Loss: 0.6932 Acc: 0.5000\n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "tensor(14944)\n",
            "Train Loss: 0.6936 Acc: 0.4981\n",
            "Val Loss: 0.6940 Acc: 0.5003\n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "tensor(15015)\n",
            "Train Loss: 0.6935 Acc: 0.5005\n",
            "Val Loss: 0.6967 Acc: 0.5000\n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "tensor(15142)\n",
            "Train Loss: 0.6938 Acc: 0.5047\n",
            "Val Loss: 0.6927 Acc: 0.5148\n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "tensor(15010)\n",
            "Train Loss: 0.6935 Acc: 0.5003\n",
            "Val Loss: 0.6930 Acc: 0.5000\n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "tensor(14936)\n",
            "Train Loss: 0.6939 Acc: 0.4979\n",
            "Val Loss: 0.6932 Acc: 0.5000\n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "tensor(14956)\n",
            "Train Loss: 0.6936 Acc: 0.4985\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "tensor(15078)\n",
            "Train Loss: 0.6938 Acc: 0.5026\n",
            "Val Loss: 0.6933 Acc: 0.5000\n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "tensor(15135)\n",
            "Train Loss: 0.6938 Acc: 0.5045\n",
            "Val Loss: 0.6938 Acc: 0.5000\n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "tensor(15122)\n",
            "Train Loss: 0.6941 Acc: 0.5041\n",
            "Val Loss: 0.6932 Acc: 0.5000\n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "tensor(15020)\n",
            "Train Loss: 0.6937 Acc: 0.5007\n",
            "Val Loss: 0.6931 Acc: 0.5000\n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "tensor(15048)\n",
            "Train Loss: 0.6935 Acc: 0.5016\n",
            "Val Loss: 0.6929 Acc: 0.5132\n",
            "\n",
            "Training complete in 0m 41s\n",
            "Best val Acc: 0.516933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXTG_QizHgkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d3a93316-cb33-4d62-9dd3-891ab1208fcb"
      },
      "source": [
        "a_net = AttackModel(3, 64).to(device)\n",
        "a_net.load_state_dict(attack_last_net)\n",
        "t_l, t_p = attack_test(attack_best_net, atk_test_loader, criterion)\n",
        "l_true = []\n",
        "l_pred = []\n",
        "for d in t_l:\n",
        "    l_list = d.cpu().numpy()\n",
        "    for l in l_list:\n",
        "        l_true.append(l)\n",
        "# print(l_true)\n",
        "for d in t_p:\n",
        "    l_list = d.cpu().numpy()\n",
        "    for l in l_list:\n",
        "        l_pred.append(l)\n",
        "# print(l_pred)\n",
        "f_mnist_acc, f_mnist_prec, f_mnist_rec = report(l_true, l_pred)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6930 Acc: 0.5169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.28      0.37     15000\n",
            "           1       0.51      0.76      0.61     15000\n",
            "\n",
            "    accuracy                           0.52     30000\n",
            "   macro avg       0.52      0.52      0.49     30000\n",
            "weighted avg       0.52      0.52      0.49     30000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[11338  3662]\n",
            " [10830  4170]]\n",
            "\n",
            "Statistical Report:\n",
            "Acc:  0.52\n",
            "Precision:  0.51\n",
            "Recall:  0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-OcdWQNrqcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "61148866-048e-41c4-f3f6-46154cf22a02"
      },
      "source": [
        "precision_list = [mnist_prec, f_mnist_prec, 0.57] # manually added precision value acheived in other script for cifar10\n",
        "recall_list = [mnist_rec, f_mnist_rec, 1.0] # manually added recall value acheived in other script for cifar10\n",
        "index = ['MNIST', 'FashionMNIST', 'Cifar10']\n",
        "df = pd.DataFrame({'Precision': precision_list,\n",
        "                   'Recall': recall_list}, index=index)\n",
        "ax = df.plot.bar(rot=0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}